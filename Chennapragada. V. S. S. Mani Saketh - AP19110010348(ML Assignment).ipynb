{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chennapragada. V. S. S. Mani Saketh\n",
    "## AP19110010348\n",
    "## CSE - C\n",
    "## ML Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a dataset\n",
    "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "y = [0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n",
    "1. Fit a linear regression and compute (i) RMSE: Root Mean Squared Error, (ii) MAE: Mean\n",
    "Absolute Error and (iii) R-Squared Error. Use both analytic formulation (matrix multiplication\n",
    "method as discussed in the class) and gradient descent-based approach and compare the\n",
    "prediction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Using Analytic Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta 1 is  79.2\n",
      "Beta 0 is  -153.90000000000003\n",
      "Predicted Values of y Using Linear Regression using analytic formulation are : \n",
      "[-153.9, -74.7, 4.5, 83.7, 162.9, 242.1, 321.3, 400.5, 479.7, 558.9]\n",
      "Root Mean Squared Error for the given data is  428.7834068617861\n",
      "Mean Absolute Error for the given data is  356.40000000000003\n",
      "R-Squared for the given data is  2.234936855857163\n"
     ]
    }
   ],
   "source": [
    "#Given\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "y = [0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n",
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n",
    "x_sum1 =0\n",
    "y_sum1 =0\n",
    "for i in x:\n",
    "    x_sum1 += abs(i - x_mean)\n",
    "for j in y:\n",
    "    y_sum1 += abs(j - y_mean)\n",
    "numerator = (x_sum1)*(y_sum1)\n",
    "den = x_sum1**2\n",
    "b1 = numerator/den\n",
    "print(\"Beta 1 is \",b1)\n",
    "b0 = y_mean - b1*(x_mean)\n",
    "print(\"Beta 0 is \",b0)\n",
    "#y1 = 202.5\n",
    "y_predicted = []\n",
    "for i in x:\n",
    "    y1 = b0 + (b1)*(i)\n",
    "    y_predicted.append(round(y1,2))\n",
    "print(\"Predicted Values of y Using Linear Regression using analytic formulation are : \")\n",
    "print(y_predicted)\n",
    "# 1. RMSE: Root Mean Squared Error\n",
    "# 2. MAE: Mean Absolute Error\n",
    "# 3. R-Squared Error\n",
    "rmse_nume = 0\n",
    "mae_nume = 0\n",
    "n = len(y_predicted)\n",
    "for i in y:\n",
    "    j = 0\n",
    "    if(j<n):\n",
    "        rmse_nume += (i - y_predicted[j])**2\n",
    "        mae_nume += abs(i - y_predicted[j])\n",
    "        j = j+1\n",
    "SSR = 0\n",
    "SST = 0\n",
    "for i in y:\n",
    "    j = 0\n",
    "    SST += (i-y_mean)**2\n",
    "    if(j<n):\n",
    "        SSR += (y_predicted[j]-y_mean)**2\n",
    "        j = j+1\n",
    "R_Squared = SSR/SST\n",
    "rmse = sqrt(rmse_nume/n)\n",
    "mae = mae_nume/n\n",
    "print(\"Root Mean Squared Error for the given data is \", rmse)\n",
    "print(\"Mean Absolute Error for the given data is \",mae)\n",
    "print(\"R-Squared for the given data is \",R_Squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Using Gradient Descent Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: %d - Error: %.4f 100 [17235.15112093  3365.22810707    85.77616302  4164.59462385\n",
      " 10364.42066551 13242.9293048   9672.73339944  2081.38364797\n",
      "  2411.36858987 36800.11460546]\n",
      "Iteration: %d - Error: %.4f 200 [18688.89750153  3884.56568261    36.66029356  3898.23323371\n",
      " 10164.045595   13270.56766202  9915.97891202  2300.16801486\n",
      "  2084.73283305 35072.98042174]\n",
      "Iteration: %d - Error: %.4f 300 [18713.8142555   3893.60550061    36.01103945  3893.83510243\n",
      " 10160.69718896 13271.03206747  9920.0897754   2303.93561919\n",
      "  2079.4501743  35044.32928519]\n",
      "Converged\n",
      "[-136.79991451  678.59984272]\n",
      "Predicted Values of y using linear regression using gradient descent are \n",
      "[-136.8, -61.4, 14.0, 89.4, 164.8, 240.2, 315.6, 391.0, 466.4, 541.8]\n",
      "Root Mean Squared Error for the given data is  414.67908073593486\n",
      "Mean Absolute Error for the given data is  339.3\n",
      "R-Squared for the given data is  2.0256181791789283\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "x = np.array([0,1,2,3,4,5,6,7,8,9],dtype=float)[:, np.newaxis]\n",
    "x = x/np.max(x)\n",
    "\n",
    "y = np.array([0,1,8,27,64,125,216,343,512,729],dtype=float)\n",
    "y_mean = np.mean(y)\n",
    "#Random data generation\n",
    "x = np.hstack((np.ones_like(x), x))\n",
    "\n",
    "#Function to compute gradient\n",
    "def get_gradient(w, x, y):\n",
    "    y_estimate = x.dot(w).flatten()\n",
    "    error = (y.flatten() - y_estimate)\n",
    "    gradient = -(1.0/float(len(x))) * (error.dot(x))\n",
    "    return gradient, error**2\n",
    "\n",
    "#Main Program\n",
    "#Weight Initialization\n",
    "w = np.random.randn(2)\n",
    "#Learning Rate initialization\n",
    "alpha = 0.5\n",
    "#Parameter for stopping criteria is fixed\n",
    "tolerance = 1e-5\n",
    "# Perform Gradient Descent\n",
    "iterations = 1\n",
    "while True:\n",
    "    gradient, error = get_gradient(w, x, y)\n",
    "    new_w = w - alpha * gradient\n",
    "    # Stopping Condition\n",
    "    if np.sum(abs(new_w - w)) < tolerance:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    # Print error every 50 iterations\n",
    "    if iterations % 100 == 0:\n",
    "        print(\"Iteration: %d - Error: %.4f\", iterations, error)\n",
    "    iterations += 1\n",
    "    w = new_w\n",
    "print(w)\n",
    "b0 = w[0]\n",
    "b1 = w[1]\n",
    "y_predicted = []\n",
    "for i in x:\n",
    "    y1 = b0 + (b1)*(i[1])\n",
    "    y_predicted.append(round(y1,2))\n",
    "print(\"Predicted Values of y using linear regression using gradient descent are \")\n",
    "print(y_predicted)\n",
    "# 1. RMSE: Root Mean Squared Error\n",
    "# 2. MAE: Mean Absolute Error\n",
    "# 3. R-Squared Error\n",
    "rmse_nume = 0\n",
    "mae_nume = 0\n",
    "n = len(y_predicted)\n",
    "for i in y:\n",
    "    j = 0\n",
    "    if(j<n):\n",
    "        rmse_nume += (i - y_predicted[j])**2\n",
    "        mae_nume += abs(i - y_predicted[j])\n",
    "        j = j+1\n",
    "SSR = 0\n",
    "SST = 0\n",
    "for i in y:\n",
    "    j = 0\n",
    "    SST += (i-y_mean)**2\n",
    "    if(j<n):\n",
    "        SSR += (y_predicted[j]-y_mean)**2\n",
    "        j = j+1\n",
    "R_Squared = SSR/SST\n",
    "rmse = pow(rmse_nume/n,1/2)\n",
    "mae = mae_nume/n\n",
    "print(\"Root Mean Squared Error for the given data is \", rmse)\n",
    "print(\"Mean Absolute Error for the given data is \",mae)\n",
    "print(\"R-Squared for the given data is \",R_Squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit a polynomial regression and compute (i) RMSE: Root Mean Squared Error, (ii) MAE:\n",
    "Mean Absolute Error and (iii) R-Squared Error. Use both analytic formulation (matrix\n",
    "multiplication method as discussed in the class) and gradient descent-based approach compare\n",
    "the prediction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression Using Analytic Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta 0 :  [-136.8]\n",
      "Beta 1 :  [75.4]\n",
      "Predicted Values of y Using Polynomial Regression using analytic formulation are : \n",
      "[-136.8, -61.4, 14.0, 89.4, 164.8, 240.2, 315.6, 391.0, 466.4, 541.8]\n",
      "Root Mean Squared Error for the given data is  414.67908073593486\n",
      "Mean Absolute Error for the given data is  339.3\n",
      "R-Squared for the given data is  2.0256181791789283\n"
     ]
    }
   ],
   "source": [
    "#Given\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "y = [0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n",
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n",
    "n1 = len(x)\n",
    "n2 = len(y)\n",
    "x_dash = np.reshape(x,(n1,1))\n",
    "y_dash = np.reshape(y,(n2,1))\n",
    "new_column = np.ones(n1)\n",
    "x_final = np.insert(x_dash, 0, new_column, axis=1)\n",
    "x_trans = np.transpose(x_final)\n",
    "f_part = x_trans.dot(x_final)\n",
    "f_final_part = np.linalg.inv(f_part)\n",
    "s_part = x_trans.dot(y_dash)\n",
    "beta = (f_final_part).dot(s_part)\n",
    "b0 = beta[0]\n",
    "b1 = beta[1]\n",
    "print(\"Beta 0 : \", b0)\n",
    "print(\"Beta 1 : \", b1)\n",
    "i = 0\n",
    "y_pred = []\n",
    "while (i < n1):\n",
    "    second = b1*(x[i])\n",
    "    y_pred.append(round(float(b0+second),2))\n",
    "    i += 1\n",
    "print(\"Predicted Values of y Using Polynomial Regression using analytic formulation are : \")\n",
    "print(y_pred)\n",
    "# 1. RMSE: Root Mean Squared Error\n",
    "# 2. MAE: Mean Absolute Error\n",
    "# 3. R-Squared Error\n",
    "rmse_nume = 0\n",
    "mae_nume = 0\n",
    "n = len(y_pred)\n",
    "for i in y:\n",
    "    j = 0\n",
    "    if(j<n):\n",
    "        rmse_nume += (i - y_pred[j])**2\n",
    "        mae_nume += abs(i - y_pred[j])\n",
    "        j = j+1\n",
    "SSR = 0\n",
    "SST = 0\n",
    "for i in y:\n",
    "    j = 0\n",
    "    SST += (i-y_mean)**2\n",
    "    if(j<n):\n",
    "        SSR += (y_pred[j]-y_mean)**2\n",
    "        j = j+1\n",
    "R_Squared = SSR/SST\n",
    "rmse = sqrt(rmse_nume/n)\n",
    "mae = mae_nume/n\n",
    "print(\"Root Mean Squared Error for the given data is \", rmse)\n",
    "print(\"Mean Absolute Error for the given data is \",mae)\n",
    "print(\"R-Squared for the given data is \",R_Squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression Using Gradient Descent Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for the given data is  1839.6719412907576\n",
      "Mean Absolute Error for the given data is  258.57887861048096\n",
      "R-Squared for the given data is  3012.1527782907083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([0, 1, 8, 27, 64, 125, 216, 343, 512, 729])\n",
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n",
    "def loss(y,y_hat):\n",
    "    loss = np.mean((y_hat - y)**2)\n",
    "    return loss\n",
    "def gradients(X,y,y_hat):\n",
    "    m = X.shape[0]\n",
    "    k = 1/m\n",
    "    dw = (k)*np.dot(X.T, (y_hat-y))\n",
    "    db = (k)*np.sum((y_hat-y))\n",
    "    return dw, db\n",
    "def x_transform(X, degrees):\n",
    "    t = X.copy()\n",
    "    for i in degrees:\n",
    "        X = np.append(X, t**i, axis = 1)\n",
    "    return X\n",
    "def train(X,y,bs,degrees,epochs,lr):\n",
    "    x = x_transform(X,degrees)\n",
    "    m = len(X)\n",
    "    n = len(X[0])\n",
    "    w = np.zeros((n,1))\n",
    "    b = 0\n",
    "    y = y.reshape(m,1)\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            y_hat = np.dot(xb,w)+b\n",
    "            dw,db = gradients(xb,yb,y_hat)\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "        l = loss(y,np.dot(x,w)+b)\n",
    "        losses.append(l)\n",
    "    return w,b,losses\n",
    "def predict(X,w,b,degrees):\n",
    "    x1 = x_transform(X,degrees)\n",
    "    return np.dot(x1,w)+b\n",
    "# 1. RMSE: Root Mean Squared Error\n",
    "# 2. MAE: Mean Absolute Error\n",
    "# 3. R-Squared Error\n",
    "rmse_nume = 0\n",
    "mae_nume = 0\n",
    "n = len(y_pred)\n",
    "for i in y:\n",
    "    j = 0\n",
    "    if(j<n):\n",
    "        rmse_nume += (i - y_pred[j])**2\n",
    "        mae_nume += abs(i - y_pred[j])\n",
    "        j = j+1\n",
    "SSR = 0\n",
    "SST = 0\n",
    "for i in y:\n",
    "    j = 0\n",
    "    SST += (i-y_mean)**2\n",
    "    if(j<n):\n",
    "        SSR += (y_pred[j]-y_mean)**2\n",
    "        j = j+1\n",
    "R_Squared = SSR/SST\n",
    "rmse = sqrt(rmse_nume/n)\n",
    "mae = mae_nume/n\n",
    "print(\"Root Mean Squared Error for the given data is \", rmse)\n",
    "print(\"Mean Absolute Error for the given data is \",mae)\n",
    "print(\"R-Squared for the given data is \",R_Squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Boston Housing Rate Dataset and split the data randomly into two disjoint subsets:\n",
    "train(.7) and test(.3). You may use following code fragments to load data in numpy variable:\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "bd = datasets.load_boston()\n",
    "X=bd.data\n",
    "Y=bd.target\n",
    "\n",
    "Attribute Information of the dataset is as follows:\n",
    "Input features in order:\n",
    "1) CRIM: per capita crime rate by town\n",
    "2) ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3) INDUS: proportion of non-retail business acres per town\n",
    "4) CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "5) NOX: nitric oxides concentration (parts per 10 million) [parts/10M]\n",
    "6) RM: average number of rooms per dwelling\n",
    "7) AGE: proportion of owner-occupied units built prior to 1940\n",
    "8) DIS: weighted distances to five Boston employment centres\n",
    "9) RAD: index of accessibility to radial highways\n",
    "10) TAX: full-value property-tax rate per $10,000 [$/10k]\n",
    "11) PTRATIO: pupil-teacher ratio by town\n",
    "12) B: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "\n",
    "13) LSTAT: % lower status of the population\n",
    "Output variable:\n",
    "1) MEDV: Median value of owner-occupied homes in $1000's [k$]\n",
    "\n",
    "### 3. Fit appropriate regression line to predict the MEDV analyze based on RMSE, MAE and R- Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "\n",
      "\n",
      "Column: CRIM\n",
      "RMSE:  14454.86147800864\n",
      "MAE:  8048.912917125013\n",
      "R square:  2473832.229512869\n",
      "\n",
      "\n",
      "\n",
      "Column: ZN\n",
      "RMSE:  39180.29591847953\n",
      "MAE:  28096.530576950194\n",
      "R square:  18187196.289616164\n",
      "\n",
      "\n",
      "\n",
      "Column: INDUS\n",
      "RMSE:  11530.394907936929\n",
      "MAE:  10433.897166198118\n",
      "R square:  1573657.5131530291\n",
      "\n",
      "\n",
      "\n",
      "Column: CHAS\n",
      "RMSE:  425.2164618628533\n",
      "MAE:  215.74251151502529\n",
      "R square:  2157.0705904227266\n",
      "\n",
      "\n",
      "\n",
      "Column: NOX\n",
      "RMSE:  198.78373462227512\n",
      "MAE:  163.9822062858926\n",
      "R square:  448.9695133116668\n",
      "\n",
      "\n",
      "\n",
      "Column: RM\n",
      "RMSE:  1174.083203565586\n",
      "MAE:  858.8270278860259\n",
      "R square:  16506.491985101195\n",
      "\n",
      "\n",
      "\n",
      "Column: AGE\n",
      "RMSE:  47295.82735550145\n",
      "MAE:  41392.29926492336\n",
      "R square:  26493477.4828078\n",
      "\n",
      "\n",
      "\n",
      "Column: DIS\n",
      "RMSE:  3535.4781140499695\n",
      "MAE:  2889.7919100376603\n",
      "R square:  148256.7489942611\n",
      "\n",
      "\n",
      "\n",
      "Column: RAD\n",
      "RMSE:  14632.408637781395\n",
      "MAE:  12682.60140544094\n",
      "R square:  2535013.4343579165\n",
      "\n",
      "\n",
      "\n",
      "Column: TAX\n",
      "RMSE:  283160.2869939431\n",
      "MAE:  241491.33407706956\n",
      "R square:  949748065.1722258\n",
      "\n",
      "\n",
      "\n",
      "Column: PTRATIO\n",
      "RMSE:  3641.957676908624\n",
      "MAE:  3009.983760816239\n",
      "R square:  156715.2452279362\n",
      "\n",
      "\n",
      "\n",
      "Column: B\n",
      "RMSE:  153379.69017277044\n",
      "MAE:  91869.09299734501\n",
      "R square:  278682691.84640473\n",
      "\n",
      "\n",
      "\n",
      "Column: LSTAT\n",
      "RMSE:  12004.339982861306\n",
      "MAE:  9617.261324163319\n",
      "R square:  1705072.496660917\n",
      "\n",
      "\n",
      "\n",
      "Polynomial Regression: \n",
      "\n",
      "\n",
      "Column: CRIM\n",
      "RMSE:  8.467029837479888\n",
      "MAE:  6.135434782608697\n",
      "R square:  0.1507932311849434\n",
      "\n",
      "\n",
      "\n",
      "Column: ZN\n",
      "RMSE:  8.570578141747177\n",
      "MAE:  6.062312252964425\n",
      "R square:  0.1298537531669318\n",
      "\n",
      "\n",
      "\n",
      "Column: INDUS\n",
      "RMSE:  8.041694350304258\n",
      "MAE:  5.776739130434777\n",
      "R square:  0.23384862004796592\n",
      "\n",
      "\n",
      "\n",
      "Column: CHAS\n",
      "RMSE:  9.045801670698546\n",
      "MAE:  6.627371541501968\n",
      "R square:  0.03075349257583662\n",
      "\n",
      "\n",
      "\n",
      "Column: NOX\n",
      "RMSE:  8.307286612941988\n",
      "MAE:  5.971521739130438\n",
      "R square:  0.18266692905230184\n",
      "\n",
      "\n",
      "\n",
      "Column: RM\n",
      "RMSE:  6.603109250849642\n",
      "MAE:  4.447865612648219\n",
      "R square:  0.4835433156437376\n",
      "\n",
      "\n",
      "\n",
      "Column: AGE\n",
      "RMSE:  8.51020150432813\n",
      "MAE:  5.984703557312251\n",
      "R square:  0.14212169018365178\n",
      "\n",
      "\n",
      "\n",
      "Column: DIS\n",
      "RMSE:  8.896406333580657\n",
      "MAE:  6.364762845849804\n",
      "R square:  0.062469681299452844\n",
      "\n",
      "\n",
      "\n",
      "Column: RAD\n",
      "RMSE:  8.49243940661921\n",
      "MAE:  6.188794466403159\n",
      "R square:  0.14559577543231078\n",
      "\n",
      "\n",
      "\n",
      "Column: TAX\n",
      "RMSE:  8.117135695381299\n",
      "MAE:  5.875830039525688\n",
      "R square:  0.21960764536810093\n",
      "\n",
      "\n",
      "\n",
      "Column: PTRATIO\n",
      "RMSE:  7.915165747742068\n",
      "MAE:  5.774051383399207\n",
      "R square:  0.2578343952500017\n",
      "\n",
      "\n",
      "\n",
      "Column: B\n",
      "RMSE:  8.661666285758752\n",
      "MAE:  6.206086956521744\n",
      "R square:  0.1111594006620797\n",
      "\n",
      "\n",
      "\n",
      "Column: LSTAT\n",
      "RMSE:  6.203431999875155\n",
      "MAE:  4.505197628458501\n",
      "R square:  0.5441532539469058\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#RMSE AND RELATED FUNCTIONS\n",
    "def RMSE(y,y_predicted):\n",
    "  rmse = 0\n",
    "  for i in range(len(y)):\n",
    "    rmse += (y[i]-y_predicted[i])**2\n",
    "  return sqrt(rmse/len(y))\n",
    "def MAE(y,y_predicted):\n",
    "  mae = 0\n",
    "  for i in range(len(y)):\n",
    "    mae += abs(y[i]-y_predicted[i])\n",
    "  return mae/len(y)\n",
    "\n",
    "def rSq(y,y_predicted):\n",
    "  meanY = y.mean()\n",
    "  ssr = 0\n",
    "  sst = 0\n",
    "  for i in range(len(y)):\n",
    "    ssr += (y_predicted[i] - meanY)**2\n",
    "    sst += (y[i] - meanY)**2\n",
    "  return (ssr/sst)\n",
    "\n",
    "#Polynomial Regression Function\n",
    "def polynomialReg(x,y):\n",
    "  x = np.array(x,dtype=float)[:, np.newaxis]\n",
    "  y = np.array(y,dtype=float)\n",
    "  x_mean = np.mean(x)\n",
    "  y_mean = np.mean(y)\n",
    "  n1 = len(x)\n",
    "  n2 = len(y)\n",
    "  x_dash = np.reshape(x,(n1,1))\n",
    "  y_dash = np.reshape(y,(n2,1))\n",
    "  new_column = np.ones(n1)\n",
    "  x_final = np.insert(x_dash, 0, new_column, axis=1)\n",
    "  x_trans = np.transpose(x_final)\n",
    "  f_part = x_trans.dot(x_final)\n",
    "  f_final_part = np.linalg.inv(f_part)\n",
    "  s_part = x_trans.dot(y_dash)\n",
    "  beta = (f_final_part).dot(s_part)\n",
    "  b0 = beta[0]\n",
    "  b1 = beta[1]\n",
    "  i = 0\n",
    "  y_pred = []\n",
    "  while (i < n1):\n",
    "      second = b1*(x[i])\n",
    "      y_pred.append(round(float(b0+second),2))\n",
    "      i += 1\n",
    "  return y_pred\n",
    "\n",
    "#Linear Regression Function\n",
    "def linearReg(x,y):\n",
    "  meanX = np.mean(x)\n",
    "  meanY = np.mean(y)\n",
    "  sumX =0\n",
    "  sumY =0\n",
    "  for i in x:\n",
    "      sumX += abs(i - meanX)\n",
    "  for j in y:\n",
    "      sumY += abs(j - meanY)\n",
    "\n",
    "  beta1 = ((sumX)*(sumY))/(sumX*2)\n",
    "  beta0 = meanY - beta1*(meanX)\n",
    "  y_predicted = []\n",
    "  for i in x:\n",
    "      y1 = beta0 + (beta1)*(i)\n",
    "      y_predicted.append(y1)\n",
    "  return y_predicted\n",
    "\n",
    "#data set\n",
    "\n",
    "ds = datasets.load_boston()\n",
    "x = pd.DataFrame(ds.data,columns=ds.feature_names)\n",
    "y = pd.Series(ds.target)\n",
    "print(\"Linear Regression: \\n\\n\")\n",
    "for i in ds.feature_names:\n",
    "  y_pred = linearReg(x[i],y)\n",
    "  print(\"Column: \"+i)\n",
    "  print(\"RMSE: \",RMSE(y,y_pred))\n",
    "  print(\"MAE: \",MAE(y,y_pred))\n",
    "  print(\"R square: \",rSq(y,y_pred))\n",
    "  print(\"\\n\\n\")\n",
    "print(\"Polynomial Regression: \\n\\n\")\n",
    "for i in ds.feature_names:\n",
    "  y_pred = polynomialReg(x[i],y)\n",
    "  print(\"Column: \"+i)\n",
    "  print(\"RMSE: \",RMSE(y,y_pred))\n",
    "  print(\"MAE: \",MAE(y,y_pred))\n",
    "  print(\"R square: \",rSq(y,y_pred))\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyse the input attributes and find out the attribute that best follow the linear relationship with the output price (analyze based on RMSE, MAE and R-Squared Error). Implement the analytic formulation to compute the coefficients of regression matrix and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: CRIM\n",
      "RMSE:  14454.86147800864\n",
      "MAE:  8048.912917125013\n",
      "R square:  2473832.229512869\n",
      "\n",
      "\n",
      "\n",
      "Column: ZN\n",
      "RMSE:  39180.29591847953\n",
      "MAE:  28096.530576950194\n",
      "R square:  18187196.289616164\n",
      "\n",
      "\n",
      "\n",
      "Column: INDUS\n",
      "RMSE:  11530.394907936929\n",
      "MAE:  10433.897166198118\n",
      "R square:  1573657.5131530291\n",
      "\n",
      "\n",
      "\n",
      "Column: CHAS\n",
      "RMSE:  425.2164618628533\n",
      "MAE:  215.74251151502529\n",
      "R square:  2157.0705904227266\n",
      "\n",
      "\n",
      "\n",
      "Column: NOX\n",
      "RMSE:  198.78373462227512\n",
      "MAE:  163.9822062858926\n",
      "R square:  448.9695133116668\n",
      "\n",
      "\n",
      "\n",
      "Column: RM\n",
      "RMSE:  1174.083203565586\n",
      "MAE:  858.8270278860259\n",
      "R square:  16506.491985101195\n",
      "\n",
      "\n",
      "\n",
      "Column: AGE\n",
      "RMSE:  47295.82735550145\n",
      "MAE:  41392.29926492336\n",
      "R square:  26493477.4828078\n",
      "\n",
      "\n",
      "\n",
      "Column: DIS\n",
      "RMSE:  3535.4781140499695\n",
      "MAE:  2889.7919100376603\n",
      "R square:  148256.7489942611\n",
      "\n",
      "\n",
      "\n",
      "Column: RAD\n",
      "RMSE:  14632.408637781395\n",
      "MAE:  12682.60140544094\n",
      "R square:  2535013.4343579165\n",
      "\n",
      "\n",
      "\n",
      "Column: TAX\n",
      "RMSE:  283160.2869939431\n",
      "MAE:  241491.33407706956\n",
      "R square:  949748065.1722258\n",
      "\n",
      "\n",
      "\n",
      "Column: PTRATIO\n",
      "RMSE:  3641.957676908624\n",
      "MAE:  3009.983760816239\n",
      "R square:  156715.2452279362\n",
      "\n",
      "\n",
      "\n",
      "Column: B\n",
      "RMSE:  153379.69017277044\n",
      "MAE:  91869.09299734501\n",
      "R square:  278682691.84640473\n",
      "\n",
      "\n",
      "\n",
      "Column: LSTAT\n",
      "RMSE:  12004.339982861306\n",
      "MAE:  9617.261324163319\n",
      "R square:  1705072.496660917\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "def RMSE(y,y_predicted):\n",
    "  rmse = 0\n",
    "  for i in range(len(y)):\n",
    "    rmse += (y[i]-y_predicted[i])**2\n",
    "  return sqrt(rmse/len(y))\n",
    "def MAE(y,y_predicted):\n",
    "  mae = 0\n",
    "  for i in range(len(y)):\n",
    "    mae += abs(y[i]-y_predicted[i])\n",
    "  return mae/len(y)\n",
    "\n",
    "def rSq(y,y_predicted):\n",
    "  meanY = y.mean()\n",
    "  ssr = 0\n",
    "  sst = 0\n",
    "  for i in range(len(y)):\n",
    "    ssr += (y_predicted[i] - meanY)**2\n",
    "    sst += (y[i] - meanY)**2\n",
    "  return (ssr/sst)\n",
    "\n",
    "def linearReg(x,y):\n",
    "  meanX = np.mean(x)\n",
    "  meanY = np.mean(y)\n",
    "  sumX =0\n",
    "  sumY =0\n",
    "  for i in x:\n",
    "      sumX += abs(i - meanX)\n",
    "  for j in y:\n",
    "      sumY += abs(j - meanY)\n",
    "\n",
    "  beta1 = ((sumX)*(sumY))/(sumX*2)\n",
    "  beta0 = meanY - beta1*(meanX)\n",
    "  y_predicted = []\n",
    "  for i in x:\n",
    "      y1 = beta0 + (beta1)*(i)\n",
    "      y_predicted.append(y1)\n",
    "  return y_predicted\n",
    "\n",
    "\n",
    "ds = datasets.load_boston()\n",
    "x = pd.DataFrame(ds.data,columns=ds.feature_names)\n",
    "y = pd.Series(ds.target)\n",
    "for i in ds.feature_names:\n",
    "  y_pred = linearReg(x[i],y)\n",
    "  print(\"Column: \"+i)\n",
    "  print(\"RMSE: \",RMSE(y,y_pred))\n",
    "  print(\"MAE: \",MAE(y,y_pred))\n",
    "  print(\"R square: \",rSq(y,y_pred))\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
